{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7798102",
   "metadata": {},
   "source": [
    "# USC CKIDS Datafest 2022 \n",
    "## Characterizing Online Attitudes, Expectations, and Concerns about Novel Medical Treatments\n",
    "\n",
    "**Source of Data:**<br>\n",
    "Manually serched in reddit for topics regarding male birth control, and downloaded the post/thread submissions with the comments in it. Also, downloaded the user history of those who commented in it. <br>\n",
    "**Data files:** <br>\n",
    "submissions : 74 posts/threads (in .pkl files) <br>\n",
    "users: 21627 user history of those who commented on the submissions (in .pkl files) <br>\n",
    "**Data exploration:** <br>\n",
    "Histogram of users commenting in more than one reddit submission. \n",
    "Vader Sentiment analysis of comments for each submission.\n",
    "Box plot and trend line for overall sentiment over time. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05965c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from praw.models import MoreComments\n",
    "from collections import defaultdict, Counter\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# import and read reddit submissions .pkl (pickle) files\n",
    "directory = '.../DATAFEST_2022/submissions/' # change directory\n",
    "submissions = []\n",
    "count = 0\n",
    "for file in os.listdir (directory):\n",
    "    if file.endswith('.pkl'):\n",
    "        with open (directory + file, 'rb') as f:\n",
    "            submissions.append(pickle.load(f))\n",
    "            count += 1   \n",
    "print ('File count:', count)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebffc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reddit data in PRAW: The Python Reddit API Wrapper\n",
    "# https://praw.readthedocs.io/en/stable/index.html\n",
    "\n",
    "class Submission:\n",
    "\n",
    "    def __init__(self,sub):\n",
    "        self.sub = sub # list of Reddit submissions\n",
    "        self.posts = list() # list of comments\n",
    "        self.pos_str = list()\n",
    "        self.neg_str = list()\n",
    "\n",
    "    def comments (self): # read all comments in each submission\n",
    "        commentors = set([])\n",
    "        for comment in self.sub.comments.list():\n",
    "            # append commentor's username, date and time, and comment text\n",
    "            self.posts.append([['username:', comment.author],dt.datetime.utcfromtimestamp(comment.created), comment.body])\n",
    "            commentors.add(str(comment.author))\n",
    "        return commentors\n",
    "    \n",
    "    def dataframe (self): # convert list into dataframe format\n",
    "        self.dframe = pd.DataFrame(self.posts)\n",
    "    \n",
    "    def VaderSentiment(self): # sentiment analysis for each comment\n",
    "        self.analyzer = SentimentIntensityAnalyzer()\n",
    "        # Sentiment analysis calculates positive, negative, neutral, and compound\n",
    "        self.sentiment = self.dframe[2].apply(lambda x: self.analyzer.polarity_scores(x)['compound'])\n",
    "        self.dframe = pd.concat([self.dframe,self.sentiment.apply(pd.Series)],axis=1)\n",
    "        return (self.sentiment)\n",
    "    \n",
    "    def list_str(self): #gets string of comments of negative and positive sentiment\n",
    "        for index, row in self.dframe.iterrows():\n",
    "            if row.iloc[-1] >= 0.9:\n",
    "                self.pos_str.append(row[2])\n",
    "            if row.iloc[-1] <= -0.9:\n",
    "                self.neg_str.append(row[2])\n",
    "    \n",
    "    def describe(self): # returns mean, min, max, and IQR of sentiment for each submission. \n",
    "        self.average=self.dframe.describe()\n",
    "        return (self.average)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0b8f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the sentiment based on the title, and sending the submission data to functions.\n",
    "\n",
    "dates = list()\n",
    "all_sub = dict()\n",
    "data_dict = dict()\n",
    "pos_str = list()\n",
    "neg_str = list()\n",
    "\n",
    "#from the list of submissions, read each submission with no limit of comments\n",
    "for sub in submissions:\n",
    "    sub.comments.replace_more (limit = None)\n",
    "    \n",
    "    if sub.num_comments > 0: # one submission had no comment, and was excluded. As long it has a comment. \n",
    "        all_sub[sub.title] = dict()\n",
    "        all_sub[sub.title]['Title'] = sub.title # submission title\n",
    "        all_sub[sub.title]['Time'] = dt.datetime.utcfromtimestamp(sub.created) # time of creation of submission\n",
    "        date = dt.datetime.utcfromtimestamp(sub.created)\n",
    "        all_sub[sub.title]['Vader'] = list()\n",
    "        \n",
    "        sub.id = Submission(sub)\n",
    "        \n",
    "        user = list(sub.id.comments())\n",
    "        all_sub[sub.title]['users'] = user #Key = submission title; value = usernames\n",
    "        sub.id.dataframe()\n",
    "        vader = sub.id.VaderSentiment()\n",
    "\n",
    "        # collect list of strings of negative and positive comments\n",
    "        data_dict[date] = vader\n",
    "        \n",
    "        sub.id.list_str()\n",
    "        pos_str.append(sub.id.pos_str)\n",
    "        neg_str.append(sub.id.neg_str)\n",
    "        \n",
    "        all_sub[sub.title]['Vader'] = sub.id.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf429dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of frequency of usernames in all 74 submissions\n",
    "user = dict()\n",
    "for k,v in all_sub.items():\n",
    "    for u in v['users']:\n",
    "        if u != 'None': # not including usersnames that was deleted or None\n",
    "            user[u] = user.get(u, 0) + 1\n",
    "#print (len (user))\n",
    "\n",
    "# users in 2, 3, 4, 5, 6 submissions\n",
    "# frequency of usernames in multiple posts\n",
    "user2, user3, user4, user5, user6 = list(), list(),list(),list(),list()\n",
    "one = 0\n",
    "for i in user:\n",
    "    if user[i] == 6: user6.append(i)\n",
    "    elif user[i] == 5: user5.append(i)\n",
    "    elif user[i] == 4: user4.append(i)\n",
    "    elif user[i] == 3: user3.append(i)\n",
    "    elif user[i] == 2: user2.append(i)\n",
    "    else:\n",
    "        one += 1\n",
    "\n",
    "print  (len(user6), len(user5),len(user4),len(user3),len(user2))      \n",
    "print (one + len(user6)+len(user5)+len(user4)+len(user3)+(len(user2)))\n",
    "\n",
    "# https://stackoverflow.com/questions/39841733/matplotlib-histogram-how-to-display-the-count-over-the-bar\n",
    "# https://python-course.eu/numerical-programming/histograms-with-matplotlib.php\n",
    "\n",
    "freq_lst = list(user.values())\n",
    "\n",
    "sns.set(rc={'figure.figsize': (20,10),'font.size':20}) \n",
    "n, bins, patches = plt.hist(x = freq_lst, edgecolor = 'black', bins = [1,2,3,4,5,6,7], align = 'left' )\n",
    "plt.bar_label(patches, fontsize = 15)\n",
    "\n",
    "plt.xticks (bins[0:6], fontsize= 'small')\n",
    "\n",
    "plt.grid(axis = 'x')\n",
    "plt.title ('Frequency of Users commenting in multiple Reddit submissions', fontsize = 'large')\n",
    "plt.ylabel ('Number of Users', fontsize = 'medium')\n",
    "plt.xlabel ('Number of Submissions', fontsize = 'medium')\n",
    "plt.yscale('log')\n",
    "\n",
    "#plt.savefig (\"users_subsv2.png\")\n",
    "plt.show()\n",
    "\n",
    "counter = dict()\n",
    "for i in freq_lst:\n",
    "    counter[i] = counter.get(i,0) + 1\n",
    "print (counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4208b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from data dictionary (key is data and time; value is sentiment value)\n",
    "# sort keys based on chronological order\n",
    "\n",
    "order = list()\n",
    "for k,v in sorted(data_dict.items()):\n",
    "    order.append(k)\n",
    "#print (order)\n",
    "\n",
    "sort_data = dict()\n",
    "for k,v in sorted(data_dict.items()):\n",
    "    sort_data[k] = v\n",
    "\n",
    "sort_df = pd.DataFrame(sort_data)\n",
    "#sort_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0d4b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table of date and title of submission\n",
    "ddd = list()\n",
    "for k,v in sorted (all_sub.items()):\n",
    "    ddd.append([v['Time'],k])\n",
    "    \n",
    "    \n",
    "dd = pd.DataFrame(ddd)\n",
    "display (dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d475e266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get summary of sentiment analysis\n",
    "des = (sort_df.describe())\n",
    "display(des)\n",
    "#des.to_csv(\"sentiment_mean.csv\")\n",
    "\n",
    "avg= []\n",
    "for i in order:\n",
    "    avg.append(des[i]['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339587b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# box plot of each submission in chronological order\n",
    "# plot of the means on each submission and trend line.\n",
    "\n",
    "sns.set_style (\"ticks\")\n",
    "sns.set(rc={'figure.figsize': (35,20), 'xtick.bottom': True})\n",
    "ax = sns.stripplot (order = order, jitter = True, size = 5, alpha = 0.5, linewidth =1, data = sort_df)\n",
    "ax = sns.boxplot(order=order, showfliers=True, linewidth=0.8, showmeans=True, data=sort_df)\n",
    "ax = sns.pointplot(order=order, data=sort_df, ci=None, color='black')\n",
    "\n",
    "plt.xlabel(\"Date & Time\", fontsize = 30)\n",
    "plt.ylabel(\"Sentiment Score\", fontsize = 30)\n",
    "labels = ax.axes.get_xticklabels()\n",
    "ax = ax.axes.set_xticklabels(labels, rotation=45)\n",
    "\n",
    "# Trend line\n",
    "xs = range (0,73)\n",
    "z = np.polyfit(xs,avg,1)\n",
    "p = np.poly1d(z)\n",
    "ax = plt.plot(xs,p(xs),color = 'Red', lw=3)\n",
    "\n",
    "plt.title(\"Sentiment Analysis over time\", fontsize = 50, fontweight='bold', pad=30)\n",
    "\n",
    "#plt.savefig('sent_box.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cef81f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(xs,p(xs),\"r--\")\n",
    "\n",
    "xs = range (1,74)\n",
    "z = np.polyfit(xs,avg,1)\n",
    "p = np.poly1d(z)\n",
    "ax = plt.plot(xs,p(xs),color = 'Red', lw=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a0b5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (type(pos_str), pos_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd387635",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# using the list of positive and negative sentiment string, remove stop words and create word cloud\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "exc = ['tl', 'dr']\n",
    "stopwords.extend(exc)\n",
    "\n",
    "pos_words = str()\n",
    "for comms in pos_str:\n",
    "    for com in comms:\n",
    "        for words in re.findall('[a-zA-Z]+', com):\n",
    "            words = words.lower().strip()\n",
    "            if words not in stopwords:\n",
    "                pos_words += \" \" + words\n",
    "            \n",
    "# print (pos_words)\n",
    "\n",
    "neg_words = str()\n",
    "for comms in neg_str:\n",
    "    for com in comms:\n",
    "        for words in re.findall('[a-zA-Z]+', com):\n",
    "            words = words.lower().strip()\n",
    "            if words not in stopwords:\n",
    "                neg_words += \" \" + words\n",
    "                            \n",
    "# print (neg_words)\n",
    "\n",
    "\n",
    "def plot_wordcloud(series,output_filename, bg, cm, title, c):\n",
    "    from wordcloud import WordCloud\n",
    "    wordcloud = WordCloud(width = 800, height = 400, background_color = bg, colormap = cm).generate(series)\n",
    "    \n",
    "    plt.figure (figsize = (20,10))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title, fontsize = 50, color= c, fontweight='bold', pad=30)\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    #wordcloud.to_file(output_filename + '.png')\n",
    "    plt.savefig(output_filename + '.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9a3758",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(pos_words,'positive', 'white', 'magma', 'Positive Sentiment Word Cloud', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9d977f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(neg_words,'negative', 'white', 'winter','Negative Sentiment Word Cloud', 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d054355",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050d6896",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
